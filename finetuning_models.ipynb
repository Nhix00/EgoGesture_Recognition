{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset parameters\n",
    "drawed = False\n",
    "\n",
    "modality = \"RGB\"\n",
    "\n",
    "#model name\n",
    "model_name = \"mobilenet\"\n",
    "\n",
    "#model parameters\n",
    "width_mult = 2.0\n",
    "\n",
    "dataset_drawed_path = \"/home/diego/Scrivania/dataset/images_Drawed\"\n",
    "\n",
    "dataset_path = \"/home/diego/Scrivania/dataset/GestureDataset/ego_gesture/images\"\n",
    "\n",
    "annotation_file_path = \"./annotation_egogesture/egogestureall.json\"\n",
    "\n",
    "path_to_ckpt = \"./ckpt/jester_\"+model_name+\"_\"+str(width_mult)+\"x_RGB_16_best.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.opts import parse_opts\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.spatial_transforms import *\n",
    "from dataset.temporal_transforms import *\n",
    "from dataset.target_transforms import ClassLabel, VideoID\n",
    "\n",
    "spatial_transform = Compose([\n",
    "            Scale(112),\n",
    "            CenterCrop(112),\n",
    "            ToTensor(1)\n",
    "        ])\n",
    "\n",
    "temporal_transform = TemporalCenterCrop(size=16, downsample = 1)\n",
    "\n",
    "target_transform = ClassLabel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: EgoGesture Dataset - validation, is loading...\n",
      "dataset loading [0/9929]\n",
      "dataset loading [1000/9929]\n",
      "dataset loading [2000/9929]\n",
      "dataset loading [3000/9929]\n",
      "dataset loading [4000/9929]\n",
      "dataset loading [5000/9929]\n",
      "dataset loading [6000/9929]\n",
      "dataset loading [7000/9929]\n",
      "dataset loading [8000/9929]\n",
      "dataset loading [9000/9929]\n",
      "[INFO]: EgoGesture Dataset - training, is loading...\n",
      "dataset loading [0/30039]\n",
      "dataset loading [1000/30039]\n",
      "dataset loading [2000/30039]\n",
      "dataset loading [3000/30039]\n",
      "dataset loading [4000/30039]\n",
      "dataset loading [5000/30039]\n",
      "dataset loading [6000/30039]\n",
      "dataset loading [7000/30039]\n",
      "dataset loading [8000/30039]\n",
      "dataset loading [9000/30039]\n",
      "dataset loading [10000/30039]\n",
      "dataset loading [11000/30039]\n",
      "dataset loading [12000/30039]\n",
      "dataset loading [13000/30039]\n",
      "dataset loading [14000/30039]\n",
      "dataset loading [15000/30039]\n",
      "dataset loading [16000/30039]\n",
      "dataset loading [17000/30039]\n",
      "dataset loading [18000/30039]\n",
      "dataset loading [19000/30039]\n",
      "dataset loading [20000/30039]\n",
      "dataset loading [21000/30039]\n",
      "dataset loading [22000/30039]\n",
      "dataset loading [23000/30039]\n",
      "dataset loading [24000/30039]\n",
      "dataset loading [25000/30039]\n",
      "dataset loading [26000/30039]\n",
      "dataset loading [27000/30039]\n",
      "dataset loading [28000/30039]\n",
      "dataset loading [29000/30039]\n",
      "dataset loading [30000/30039]\n",
      "[INFO]: EgoGesture Dataset - testing, is loading...\n",
      "dataset loading [0/10364]\n",
      "dataset loading [1000/10364]\n",
      "dataset loading [2000/10364]\n",
      "dataset loading [3000/10364]\n",
      "dataset loading [4000/10364]\n",
      "dataset loading [5000/10364]\n",
      "dataset loading [6000/10364]\n",
      "dataset loading [7000/10364]\n",
      "dataset loading [8000/10364]\n",
      "dataset loading [9000/10364]\n",
      "dataset loading [10000/10364]\n"
     ]
    }
   ],
   "source": [
    "from dataset.dataset import get_test_set, get_training_set\n",
    "\n",
    "if drawed:\n",
    "    path_to_dataset = dataset_drawed_path\n",
    "else:\n",
    "    path_to_dataset = dataset_path\n",
    "\n",
    "assert modality in ['RGB', 'Depth'], \"Modality not supported\"\n",
    "\n",
    "val_dataset = get_test_set(path_to_dataset,\n",
    "                       annotation_file_path,\n",
    "                       spatial_transform,\n",
    "                       temporal_transform,\n",
    "                       target_transform,\n",
    "                       n_val_samples=1,\n",
    "                       test_subset= \"val\",\n",
    "                       modality=modality\n",
    "                       )\n",
    "\n",
    "train_dataset = get_training_set(video_path=path_to_dataset,\n",
    "                       annotation_path= annotation_file_path,\n",
    "                       spatial_transform=spatial_transform,\n",
    "                       temporal_transform=temporal_transform,\n",
    "                       target_transform=target_transform,\n",
    "                       modality=modality\n",
    "                       )\n",
    "\n",
    "test_set = get_test_set(path_to_dataset,\n",
    "                       annotation_file_path,\n",
    "                       spatial_transform,\n",
    "                       temporal_transform,\n",
    "                       target_transform,\n",
    "                       n_val_samples=1,\n",
    "                       test_subset= \"test\",\n",
    "                       modality=modality\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating train dataloader...\n",
      "creating val dataloader...\n",
      "creating test dataloader...\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"creating train dataloader...\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=False, num_workers=12)\n",
    "\n",
    "print(\"creating val dataloader...\")\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=12)\n",
    "\n",
    "print(\"creating test dataloader...\")\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.config import get_model\n",
    "\n",
    "model = get_model(model_name, width_mult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from models.custom_trainer import CustomTrainer\n",
    "\n",
    "path = torch.load(path_to_ckpt, map_location=torch.device('cuda'))\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=[0],)\n",
    "\n",
    "model.load_state_dict(path[\"state_dict\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import get_classifier_layer\n",
    "\n",
    "model.module.classifier = get_classifier_layer(model_name, width_mult)\n",
    "\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): MobileNet(\n",
      "    (features): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv3d(3, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Block(\n",
      "        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=64, bias=False)\n",
      "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): Block(\n",
      "        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=128, bias=False)\n",
      "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): Block(\n",
      "        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): Block(\n",
      "        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=256, bias=False)\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): Block(\n",
      "        (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512, bias=False)\n",
      "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (6): Block(\n",
      "        (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=512, bias=False)\n",
      "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (7): Block(\n",
      "        (conv1): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1024, bias=False)\n",
      "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (8): Block(\n",
      "        (conv1): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1024, bias=False)\n",
      "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (9): Block(\n",
      "        (conv1): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1024, bias=False)\n",
      "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (10): Block(\n",
      "        (conv1): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1024, bias=False)\n",
      "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (11): Block(\n",
      "        (conv1): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1024, bias=False)\n",
      "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (12): Block(\n",
      "        (conv1): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1024, bias=False)\n",
      "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (13): Block(\n",
      "        (conv1): Conv3d(2048, 2048, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=2048, bias=False)\n",
      "        (bn1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(2048, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Dropout(p=0.2, inplace=False)\n",
      "      (1): Linear(in_features=2048, out_features=84, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type               | Params\n",
      "------------------------------------------------\n",
      "0 | model    | DataParallel       | 13.0 M\n",
      "1 | accuracy | MulticlassAccuracy | 0     \n",
      "2 | ce_fn    | CrossEntropyLoss   | 0     \n",
      "------------------------------------------------\n",
      "13.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "13.0 M    Total params\n",
      "52.189    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   9%|▊         | 20/235 [00:11<02:03,  1.74it/s, v_num=5]         "
     ]
    }
   ],
   "source": [
    "from datetime import datetime \n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=10, verbose=False, mode=\"min\")\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "trainer = CustomTrainer(model = model, num_classes= 84)\n",
    "\n",
    "trainer.fit(train_loader=train_loader, val_loader=val_loader, max_epochs=EPOCHS, callbacks=[early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 81/81 [00:22<00:00,  3.57it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.8267078399658203\n",
      "        test_loss           0.7519878149032593\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.7519878149032593, 'test_acc': 0.8267078399658203}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(test_loader = test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
